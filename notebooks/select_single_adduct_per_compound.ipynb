{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "polarity = \"positive\"\n",
    "c18_standards_df = pd.read_csv('./C18_standards_' + polarity + '.tsv', sep='\\t', float_precision='round_trip')\n",
    "mass_file = pd.read_csv('./select_single_adduct_per_compound_data/inchi-key_to_mass.csv', sep=',', float_precision='round_trip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicates of different features (columns)\n",
    "\n",
    "c18_standards_df_dups = c18_standards_df.copy()\n",
    "c18_standards_df_dups = pd.merge(c18_standards_df_dups, mass_file, how=\"inner\", on=\"inchi_key\")\n",
    "\n",
    "c18_standards_df_dups['inchi-adduct'] = c18_standards_df_dups['inchi_key'].astype(str) + c18_standards_df_dups['adduct']\n",
    "c18_standards_df_dups['label-adduct'] = c18_standards_df_dups['label'].astype(str) + c18_standards_df_dups['adduct']\n",
    "duplicated_inchi_adducts = list(c18_standards_df_dups[c18_standards_df_dups['inchi-adduct'].duplicated()]['inchi-adduct'].drop_duplicates().values)\n",
    "duplicated_inchis = list(c18_standards_df_dups[c18_standards_df_dups['inchi_key'].duplicated()]['inchi_key'].drop_duplicates().values)\n",
    "duplicated_label_adducts = list(c18_standards_df_dups[c18_standards_df_dups['label-adduct'].duplicated()]['label-adduct'].drop_duplicates().values)\n",
    "duplicated_mz_isomers = list(c18_standards_df_dups[c18_standards_df_dups['mono_isotopic_molecular_weight'].round(decimals=6).duplicated()]['mono_isotopic_molecular_weight'].drop_duplicates().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify inchi keys that have multiple adducts and choose hydrogen (most common) or the highest intensity\n",
    "\n",
    "if polarity == \"positive\":\n",
    "    preferred_adduct = '[M+H]+'\n",
    "elif polarity == \"negative\":\n",
    "    preferred_adduct = '[M-H]-'\n",
    "\n",
    "c18_standards_df_filt1 = c18_standards_df_dups.copy()\n",
    "\n",
    "starting_compounds = c18_standards_df_filt1.shape\n",
    "removed_compounds = 0\n",
    "\n",
    "c18_standards_df_filt1 = c18_standards_df_filt1[~c18_standards_df_filt1['inchi_key'].isin(duplicated_inchis)]\n",
    "\n",
    "for inchi in duplicated_inchis:\n",
    "\n",
    "    adducts = list(c18_standards_df_dups[c18_standards_df_dups['inchi_key'] == inchi]['adduct'])\n",
    "    number_of_duplicates = len(adducts)\n",
    "\n",
    "    if not all(i == adducts[0] for i in adducts):\n",
    "\n",
    "        if preferred_adduct in adducts:\n",
    "\n",
    "            inchi_sub = c18_standards_df_dups[c18_standards_df_dups['inchi_key'] == inchi]\n",
    "            best_adduct = inchi_sub[inchi_sub['adduct'] == preferred_adduct].iloc[[0]]\n",
    "            c18_standards_df_filt1 = pd.concat([c18_standards_df_filt1, best_adduct], ignore_index=True)\n",
    "            print(colored(\"Choosing \" + preferred_adduct + \" for duplicated \" + inchi, \"green\"))\n",
    "            removed_compounds += number_of_duplicates-1\n",
    "\n",
    "        else:\n",
    "\n",
    "            best_adduct = c18_standards_df_dups[c18_standards_df_dups['inchi_key'] == inchi].sort_values('intensity', ascending = False).iloc[[0]]\n",
    "            c18_standards_df_filt1 = pd.concat([c18_standards_df_filt1, best_adduct], ignore_index=True)\n",
    "            print(colored(\"Warning: No \" + preferred_adduct + \" for \" + inchi + \". Choosing \" + str(best_adduct['adduct'].to_list()) + \" based on intensity\", \"red\"))\n",
    "            removed_compounds += number_of_duplicates-1\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(colored(\"Warning: all adducts for duplicated inchi key are the same!\", \"red\"))\n",
    "\n",
    "if c18_standards_df_filt1.shape[0] == starting_compounds[0]-removed_compounds:\n",
    "\n",
    "    print(colored(\"\\nCorrect number of duplicated inchis removed!\", \"green\"))\n",
    "\n",
    "else:\n",
    "\n",
    "    print(colored(\"\\nDifferent number of duplicated inchis removed than expected! Need to investigate\", \"red\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if isomers have different adducts\n",
    "\n",
    "isomers_with_differing_adducts = []\n",
    "\n",
    "for isomer_mz in duplicated_mz_isomers:\n",
    "\n",
    "    subset = c18_standards_df_filt1[c18_standards_df_filt1['mono_isotopic_molecular_weight'] == isomer_mz]\n",
    "    inchi = list(subset['inchi_key'])\n",
    "    adducts = list(subset['adduct'])\n",
    "    same_adducts = all(i == adducts[0] for i in adducts)\n",
    "\n",
    "    if same_adducts == False:\n",
    "\n",
    "        print(colored(\"Warning! Isomers (\" + str(inchi) + \") of mass \" + str(isomer_mz) + \" have different adducts (\" + str(adducts) + \")!\", \"red\"))\n",
    "        isomers_with_differing_adducts.append(inchi)\n",
    "\n",
    "        if len(adducts) == 2:\n",
    "\n",
    "            diff = (subset['rt_peak'].iloc[0] - subset['rt_peak'].iloc[1])\n",
    "\n",
    "            if abs(diff) <= 0.5:\n",
    "\n",
    "                print(colored(\"Warning! Isomers with differing adducts elute together\", \"cyan\"))\n",
    "    else:\n",
    "\n",
    "        pass\n",
    "        #print(colored(\"All good! Isomers at MZ \" + str(isomer_mz) + \" have the same adduct!\", \"green\"))\n",
    "\n",
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]\n",
    "\n",
    "isomers_with_differing_adducts = flatten(isomers_with_differing_adducts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify inchi_keys that have multiple adducts and choose the highest intensity\n",
    "\n",
    "c18_standards_df_filt1 = c18_standards_df_dups.copy()\n",
    "\n",
    "starting_compounds = c18_standards_df_filt1.shape\n",
    "removed_compounds = 0\n",
    "\n",
    "c18_standards_df_filt1 = c18_standards_df_filt1[~c18_standards_df_filt1['inchi_key'].isin(duplicated_inchis)]\n",
    "\n",
    "for inchi in duplicated_inchis:\n",
    "\n",
    "    adducts = list(c18_standards_df_dups[c18_standards_df_dups['inchi_key'] == inchi]['adduct'])\n",
    "    number_of_duplicates = len(adducts)\n",
    "\n",
    "    if any(i in isomers_with_differing_adducts for i in inchi): # Do the duplicate inchis plus adducts have isomers with differing adducts? If so, keep all\n",
    "        \n",
    "        retained_entries = c18_standards_df_dups[c18_standards_df_dups['inchi_key'].isin(inchi)]\n",
    "        print(colored(\"Retaining all adducts (\" + str(adducts) + \" for \" + inchi + \" because there are isomers with differing adducts\", \"red\"))\n",
    "        c18_standards_df_filt1 = pd.concat([c18_standards_df_filt1, retained_entries], ignore_index=True)\n",
    "\n",
    "    if not all(i == adducts[0] for i in adducts):\n",
    "\n",
    "        best_adduct = c18_standards_df_dups[c18_standards_df_dups['inchi_key'] == inchi].sort_values('intensity', ascending = False).iloc[[0]]\n",
    "        c18_standards_df_filt1 = pd.concat([c18_standards_df_filt1, best_adduct], ignore_index=True)\n",
    "        print(colored(\"Filtering to best adduct (\" + str(best_adduct['adduct'].to_list()) + \")\" + \" for duplicated \" + inchi + \" by intensity\", \"green\"))\n",
    "        removed_compounds += number_of_duplicates-1\n",
    "\n",
    "if c18_standards_df_filt1.shape[0] == starting_compounds[0]-removed_compounds:\n",
    "\n",
    "    print(colored(\"\\nCorrect number of duplicated inchis removed!\", \"green\"))\n",
    "\n",
    "else:\n",
    "\n",
    "    print(colored(\"\\nDifferent number of duplicated inchis removed than expected! Need to investigate\", \"red\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if label-adduct pairs have different MZs\n",
    "# Look for red to indicate filtering needs to be done\n",
    "\n",
    "for label_adduct in duplicated_label_adducts:\n",
    "\n",
    "    mzs = list(c18_standards_df_filt1[c18_standards_df_filt1['label-adduct'] == label_adduct]['mono_isotopic_molecular_weight'])\n",
    "    same_mz = all(i == mzs[0] for i in mzs)\n",
    "\n",
    "    if same_mz == False:\n",
    "\n",
    "        print(colored(\"Warning! Identical compound labels at mass \" + str(mzs[0]) + \" have different adducts!\", \"red\"))\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(colored(\"Identical compound labels at mass \" + str(mzs[0]) + \" have the same adduct!\", \"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if compounds with same label but different inchi_keys have the same adduct\n",
    "# Look for red to indicate filtering needs to be done\n",
    "\n",
    "duplicated_labels = list(c18_standards_df_filt1[c18_standards_df_filt1['label'].duplicated()]['label'].drop_duplicates().values)\n",
    "\n",
    "for label in duplicated_labels:\n",
    "\n",
    "    adducts = list(c18_standards_df_filt1[c18_standards_df_filt1['label'] == label]['adduct'])\n",
    "    same_adducts = all(i == adducts[0] for i in adducts)\n",
    "\n",
    "    if same_mz == False:\n",
    "\n",
    "        print(colored(\"Warning! Duplicated label \" + label + \" has different adducts!\", \"red\"))\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(colored(\"Duplicated label \" + label + \" has the same adduct!\", \"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify duplicated labels which have different first-14 inchi keys\n",
    "\n",
    "c18_standards_df_filt2 = c18_standards_df_filt1.copy()\n",
    "\n",
    "starting_compounds = c18_standards_df_filt2.shape\n",
    "removed_compounds = 0\n",
    "\n",
    "for label in duplicated_labels:\n",
    "\n",
    "    inchis = list(c18_standards_df_filt2[c18_standards_df_filt2['label'] == label]['inchi_key'])\n",
    "    \n",
    "    if inchis:\n",
    "\n",
    "        number_of_duplicates = len(inchis)\n",
    "        first14 = [i.split('-', 1)[0] for i in inchis]\n",
    "        \n",
    "        if all(i == first14[0] for i in first14):\n",
    "\n",
    "            c18_standards_df_filt2 = c18_standards_df_filt2[~c18_standards_df_filt2['label'].isin([label])]\n",
    "\n",
    "            best_label = c18_standards_df[c18_standards_df['label'] == label].sort_values('intensity', ascending = False).iloc[[0]]\n",
    "            print(colored(\"Multiple entries for \" + label + \" have identical inchi key prefixes \" + \"(\" + first14[0] + \")\" + \"; \" + \"Returning only highest intensity entry: \" + best_label['inchi_key'].to_list()[0], \"red\"))\n",
    "\n",
    "            c18_standards_df_filt2 = pd.concat([c18_standards_df_filt2, best_label], ignore_index=True)\n",
    "            removed_compounds += number_of_duplicates-1\n",
    "\n",
    "        else:\n",
    "\n",
    "            print(colored(\"Inchi keys for duplicated label \" + label + \" do not have the same prefix (\" + str(first14) + \"): Retaining all\", \"green\"))\n",
    "\n",
    "if c18_standards_df_filt2.shape[0] == starting_compounds[0]-removed_compounds:\n",
    "\n",
    "    print(colored(\"\\nCorrect number of duplicated labels removed!\", \"green\"))\n",
    "\n",
    "else:\n",
    "\n",
    "    print(colored(\"\\nDifferent number of duplicated labels removed than expected! Need to investigate\", \"red\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "c18_standards_df_filt3 = c18_standards_df_filt2.drop('label-adduct', axis=1)\n",
    "\n",
    "c18_standards_df_filt3.to_csv('C18_standards_' + polarity + '_reduced.tsv', sep='\\t', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metatlas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
